{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a01fae-0e4d-4374-b207-8e5636095db9",
   "metadata": {},
   "source": [
    "## Lesson 14 â€” AI-assisted development\n",
    "\n",
    "Headlines, and more headlines...\n",
    "\n",
    "> AI boom is in early bubble phase, [**Reuters**](https://www.reuters.com/business/ai-boom-is-early-bubble-phase-bridgewater-founder-ray-dalio-says-2026-01-05/)\n",
    "\n",
    "> Nvidia CEO predicts the death of coding, [**Techradar**](https://www.techradar.com/pro/nvidia-ceo-predicts-the-death-of-coding-jensen-huang-says-ai-will-do-the-work-so-kids-dont-need-to-learn)\n",
    "\n",
    "> 'Vibe coding' named Collins Dictionary's Word of the Year, [**CNN Business**](https://edition.cnn.com/2025/11/06/tech/vibe-coding-collins-word-year-scli-intl)\n",
    "\n",
    "> AI startup Cursor raises \\\\$2.3 billion funding round at \\\\$29.3 billion valuation, [**CNBC**](https://www.cnbc.com/2025/11/13/cursor-ai-startup-funding-round-valuation.html)\n",
    "\n",
    "Is AI relevant for us developers? Will it replace us entirely? Is the hype justified, or just hot air? Can I use it for data science?\n",
    "\n",
    "In this lesson, we will cover some of the concepts surrounding AI for software development, so that you can leverage it as a tool to increase your productivity and output quality.\n",
    "\n",
    "Readings:\n",
    "\n",
    "- [_How to write a great agents.md_, by Github](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/)\n",
    "- [_Best practices for agentic coding_, by Claude Code](https://www.anthropic.com/engineering/claude-code-best-practices)\n",
    "- [_We did the math on AI's energy footprint. Here's the story you haven't heard._, by MIT Technology Review](https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/)\n",
    "- [_Prompts.chat_, by f (prompt collection)](https://prompts.chat)\n",
    "\n",
    "Topics covered:\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Interacting with an LLM](#Interacting-with-an-LLM)\n",
    "- [Prompts](#Prompts)\n",
    "- [Agents](#Agents)\n",
    "- [Tools](#Tools)\n",
    "- [Ethics and Sustainability](#Ethics-and-Sustainability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cc55c-f975-4f99-91f5-c5b2d65c3e6e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Is AI a bubble or a technological revolution?\n",
    "\n",
    "> It's clearly both â€” **Linus Torvalds**\n",
    "\n",
    "Let's lay some common ground: **language models are predictors for the next token**. They have a state, called the context window, and are able to remember certain context based on how big this state is allowed to be.\n",
    "\n",
    "Tokens are units that language models use to process text. The word 'strawberry' might be split into tokens like `['straw', 'berry']`, or 'understanding' into `['understand', 'ing']`. Common words are usually single tokens, while rare words get split into multiple pieces. This is why AI sometimes struggles with tasks like 'count the letters in strawberry' - it doesn't see individual letters.\n",
    "\n",
    "One of the things that made language models so good at executing tasks are the attention models, that give different weights to different parts of the text, making predictions more accurate. This means these next token prediction can use information which is more relevant to the current prediction task, rather than considering the whole text. This is what allows modern LLMs to perform so well on tasks, even when the context window grows.\n",
    "\n",
    "Another thing is that the models became extremely dense in information, requiring hundreds of hours of training in large data centers, which in turn increased resource usage. Models nowadays include more information than ever in their training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f109de48453f9f5",
   "metadata": {},
   "source": [
    "### What are the limitations?\n",
    "\n",
    "Recently, Deloitte has been called to refund the Australian government in $440,000 report ([text](https://www.theguardian.com/australia-news/2025/oct/06/deloitte-to-pay-money-back-to-albanese-government-after-using-ai-in-440000-report) and [video](https://www.youtube.com/watch?v=oN0nViY4gn4) sources). The reason? The report has enhanced and had some entire parts written by AI models. Some patterns emerged from the investigation:\n",
    "\n",
    "- Footnotes that were completely fabricated, using fictional books attributed to real people.\n",
    "- AI also referred to a key court case, but misquoted the judge.\n",
    "- It made up the name of another judge.\n",
    "- Multiple made up citations on the same report.\n",
    "\n",
    "It was very clear by the specialists that those \"fabricated entries\" were caused by AI hallucinations. Despite the controversy, Deloitte repeated the feat in Canada, being accused of [citing AI generated research in a million dollar report for a Canadian provincial government](https://theindependent.ca/news/lji/major-n-l-healthcare-report-contains-errors-likely-generated-by-a-i/). The papers simply did not exist.\n",
    "\n",
    "When working with particular data, LLMs can also be [overwhelmed by too much information](https://www.ibm.com/think/topics/context-window), and right now there is a sweet spot of how big this context window can be without impacting performance too much. This means that, as of now, AI systems are limited to their context size, and can start \"forgetting things\" when the data goes out of this context window.\n",
    "\n",
    "As said, the prediction of the text token is one characteristic that all LLMs, have in common, meaning that AI does not know anything: it will try to fix the next empty space with something that is _likely_ to be the correct answer. Here is a great example, where its internal knowledge conflicts with reality:\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/chatgpt-hallucination.png\" width=\"60%\"/>\n",
    "</center>\n",
    "\n",
    "Based on these premises, we can then compile a list of things that LLMs **are not good at** (by itself):\n",
    "\n",
    "- It is **not able to provide grounded information**: there is always the possibility the content being non-sense.\n",
    "- A language model deals with **language**, and it is not able to do arithmetic calculations. It has no concept of numbers either, and due to tokenization mostly no clear concept of letters (e.g., one famous example was the task _\"how many r's in the word 'strawberry'?\"_, where AI used to fail due to the nature of tokenization, that converts _strawberry_ into a single token).\n",
    "- Similar to the previous point, it is not able to decide **what code is correct, and which isn't**.\n",
    "- Since every output is probabilistic, LLMs **cannot provide consistent output**: consecutive queries, with the same context will yield different results.\n",
    "- LLMs **have trouble keeping up to date with information** that was not present in training data: non-public frameworks and libraries that are updated often suffer from outdated content generated by the models, due to knowledge cutoff.\n",
    "- Similar to the previous point, **languages with low training data cannot provide good output**.\n",
    "\n",
    "We are also going to cover ways in which we can overcome some of those problems. For example, for the problem of _arithmetic calculations_, the LLM _can_ compute all mathematical expressions using a calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176323771488ecb3",
   "metadata": {},
   "source": [
    "### What is it good at?\n",
    "\n",
    "As many of you may have experienced: LLMs are great at a wide range of tasks surrounding software development. I'll just list a few:\n",
    "\n",
    "- **Planning of implementation**: doing concepts on what the software should look like, interface design, generation of UML models.\n",
    "- **Generation of code boilerplate**: code that is necessary for an application to work but is very repetitive.\n",
    "- **Generation of common algorithms**: tasks like data analysis and API implementation, where examples are abundant, tend to offer good results. Often, the result will offer quality that you could expect from a more experienced developer, as long as the problem is well-defined with clear requirements.\n",
    "- **Code review and debugging**: it can accurately identify antipatterns in the code, as well as suggest improvements. It can also identify bugs early, and able to spot issues in the code based on the errors you received.\n",
    "- **Learning companion**: explains unfamiliar concepts, deep-dives into code bases to provide high-level summaries.\n",
    "- **Documentation and communication**: summarizes changes in a human-readable manner, generates/updates documentation for complex functions.\n",
    "- **Quality review**: able to ensure good quality by being critical of your work, and suggesting improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1109bc13df6d14",
   "metadata": {},
   "source": [
    "## Interacting with an LLM\n",
    "\n",
    "### Chat\n",
    "\n",
    "This is the standard way of interacting with any LLM: you are presented with a chat-like interface and are able to directly input context for the LLM to evaluate an output.\n",
    "\n",
    "Nowadays, LLMs employ multiple internal tools that enhance this functionality. For example, Claude is able to generate a script (an artifact) that you can download or run in a confined environment.\n",
    "\n",
    "The chat is very useful for brainstoming approaches and planning steps, but is not able to integrate well into code development, as you as the developer are tasked with copy-pasting content and placing it in the correct place.\n",
    "\n",
    "![AI Claude Chat](../images/ai-claude-chat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea167a61963b82",
   "metadata": {},
   "source": [
    "### IDE Integration\n",
    "\n",
    "As a next step, programmers came up with plugins that can directly integrate into your IDE. They have the advantage of providing your existing code as context for your prompts and require less copy-pasting, as they have their own algorithms for code replacement.\n",
    "\n",
    "This has many advantages over using the chat, but also has its limitations: you can only work with files that you specifically passed to the plugin, so you have to manually decide what needs to be changed and where. It is not able to plan and execute tasks by itself:\n",
    "\n",
    "![AI IDE Plugin](../images/ai-ide-plugin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee178f43-8401-41cf-8e49-a01fbd34e06b",
   "metadata": {},
   "source": [
    "## API Usage\n",
    "\n",
    "You can build and integrate your own solutions using an **API Key** that can directly call a provider endpoint and get responses for prompts. There are already thousands of integrations out there capable of doing just that, that implement all sorts of applications: Telegram bots, remote code assistants, email sorters, etc.\n",
    "\n",
    "The goal here is to allow you to **build your own products** with an interface that can be used programmatically. Frameworks like [langchain-ai/langchain](https://github.com/langchain-ai/langchain) focus on providing the building blocks for creating your own agents for decision making, RAG, etc. \n",
    "\n",
    "One other example is the `jupyter-ai` integration that connects to multiple providers and is able to generate responses directly on a Jupyter notebook.\n",
    "\n",
    "Note that the **API usage is subject to its own billing**: even if you don't have to pay for the free tier of an LLM, the API user pay per consumption, usually in batches of 1M tokens. For small projects, free tiers often suffice, but production applications need to budget for API costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db65cda7916b5b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T19:47:01.137528Z",
     "start_time": "2026-01-08T19:47:00.893946Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter-ai-magics\n",
      "  Using cached jupyter_ai_magics-2.31.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: click<9,>=8.1.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (8.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=5.2.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (8.7.1)\n",
      "Requirement already satisfied: ipython in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (9.8.0)\n",
      "Requirement already satisfied: jsonpath-ng<2,>=1.5.3 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (1.7.0)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (0.3.31)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3,>=2.10.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jupyter-ai-magics) (2.12.5)\n",
      "Requirement already satisfied: ply in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jsonpath-ng<2,>=1.5.3->jupyter-ai-magics) (3.11)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.3.81)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.6.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (2.0.45)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (0.4.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (1.0.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.13.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (4.10.0)\n",
      "Requirement already satisfied: certifi in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from pydantic<3,>=2.10.0->jupyter-ai-magics) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from pydantic<3,>=2.10.0->jupyter-ai-magics) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from pydantic<3,>=2.10.0->jupyter-ai-magics) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (2.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->jupyter-ai-magics) (1.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from importlib-metadata>=5.2.0->jupyter-ai-magics) (3.23.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.0->jupyter-ai-magics) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from ipython->jupyter-ai-magics) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->jupyter-ai-magics) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython->jupyter-ai-magics) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from pexpect>4.3->ipython->jupyter-ai-magics) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->jupyter-ai-magics) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->jupyter-ai-magics) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/brunno.vanelli/Documents/git/python-for-data-analysis/venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->jupyter-ai-magics) (0.2.3)\n",
      "Using cached jupyter_ai_magics-2.31.7-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: jupyter-ai-magics\n",
      "Successfully installed jupyter-ai-magics-2.31.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"jupyter-ai-magics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbabdeb732dea072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_ai_magics extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_ai_magics\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9641d0a0955a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def fibonacci(n):\n",
       "    if n <= 0:\n",
       "        return []\n",
       "    elif n == 1:\n",
       "        return [0]\n",
       "    elif n == 2:\n",
       "        return [0, 1]\n",
       "    else:\n",
       "        fibs = fibonacci(n - 1)\n",
       "        fibs.append(fibs[-1] + fibs[-2])\n",
       "        return fibs\n",
       "\n",
       "# Example usage\n",
       "n = 10  # Change this value for different lengths of Fibonacci sequence\n",
       "print(fibonacci(n))\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-4o-mini",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-4o-mini\n",
    "Generate the recursive python function to calculate the first n fibonacci numbers and print them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72145a-b1de-4616-8603-eeb62494592f",
   "metadata": {},
   "source": [
    "### Agentic mode\n",
    "\n",
    "So far, the most advanced way of developing is the so called agentic mode: your AI _agent_ leverages not only the tasks of generating code, but also all the other aspects of software development:\n",
    "\n",
    "- Enhancing the basic prompt with information from your code base.\n",
    "- Generating a plan to achieve the desired output.\n",
    "- Using tools to interact with your development environment: it is able to read and write files, research the internet, use MCP servers, etc.\n",
    "- It iterates multiple times on the task at hand, until it considers the task finished.\n",
    "\n",
    "![](../images/ai-claude-code-workflow.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8817b0-3b07-416b-922b-17aca65376d3",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "It was clear very quickly that the **quality of the prompts increase the quality of the responses**. This makes sense if you consider that the LLM can only generate information based on what it has as context. We also saw that LLM can start hallucinating when there is too much information on the context window, and the models tend to prioritize information at the beginning or end of this window. Without good context, the **AI is simply guessing**.\n",
    "\n",
    "Here are a couple of examples of dos and don'ts:\n",
    "\n",
    "| â›” Avoid                                                  | âœ… Do instead                                                                                                                                                                                                                          |\n",
    "|----------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| The code doesn't work, fix it.                           | There is a TypeError on line 53. Cover the case where the value <br> for `y` can be null and add relevant tests.                                                                                                                      |\n",
    "| Optimize the function `fibo`                             | Optimize the function `fibo` located under `examples/fibo.py`. <br> Consider that the provided number `n` could be big and avoid recursion.                                                                                           |\n",
    "| _Closing the conversation._                              | _Resume/refine the previous conversations to resume context._ <br> _If needed, you can jump back to a previous point in time_                                                                                                         |\n",
    "| Load, transform and analyze the csv data in this folder. | Look at the structure of the CSV file and create a detailed plan to analyze the data. <br> Think hard. Write the detailed plan under `DATA_ANALYSIS.md`. Do not modify any other files.                                               |\n",
    "| Add tests for foo.py                                     | Write a new test case for foo.py, covering the edge case where the user is logged out. Avoid mocks.                                                                                                                                   |\n",
    "| Add a new function to read Excel data                    | Write a new function to load data from a Excel file. <br> Use the function `load_csv` as a template, using the same library and return format. <br> Load only data from the first sheet, and raise an error it if the sheet is empty. |\n",
    "\n",
    "Exactness here is especially important when working on existing projects. E.g:\n",
    "\n",
    "- When working with frontend projects, the screen designs might not reflect the brand.\n",
    "- When working with backend project, the data models and endpoint choices might not be fitting with existing ones.\n",
    "\n",
    "According to the showcase entitled [_Vibecoding_, by Rho Eight](https://vibecoding-rho-eight.vercel.app/), it is always important to provide:\n",
    "\n",
    "- **Context:** the role and the goal you want to achieve.\n",
    "- **Requirements:** what libraries should be used, what testing environments, what standards to follow.\n",
    "- **Examples:** showing by example is easier than describing.\n",
    "- **Output**: how the code should be formatted, which guidelines to follow, file structure, etc.\n",
    "\n",
    "### System prompts\n",
    "\n",
    "Of course, most models will already include **system prompts** that are computed on standard requests. They set context, behaviour and/or persona for the assistants. They can also serve to impose barriers and ethical guidance on what the model can handle.\n",
    "\n",
    "Here is the example of the [LLama 2 system prompt (page 56, table 32)](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/):\n",
    "\n",
    "> You are a helpful, respectful and honest assistant. Always answer as helpfully\n",
    "as possible, while being safe. Your answers should not include any harmful,\n",
    "unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that\n",
    "your responses are socially unbiased and positive in nature.\n",
    ">\n",
    "> If a question does not make any sense, or is not factually coherent, explain why\n",
    "instead of answering something not correct. If you donâ€™t know the answer to a\n",
    "question, please donâ€™t share false information.\n",
    "\n",
    "See [x1xhlol/system-prompts-and-models-of-ai-tools](https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools) how complex the basic system prompts have become for some of the models. I'll mention some segments from the [Claude Code system prompt](https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools/blob/6b2157ca3eaa6e562cd457a88770dc307c0933f1/Anthropic/Claude%20Code/Prompt.txt) that are relevant as examples of good, direct prompts:\n",
    "\n",
    "> IMPORTANT: Assist with defensive security tasks only. Refuse to create, modify, or improve code that may be used maliciously\n",
    "\n",
    "> You MUST answer concisely with fewer than 4 lines (not including tool use or code generation), unless user asks for detail.\n",
    "\n",
    "> IMPORTANT: You should minimize output tokens as much as possible while maintaining helpfulness, quality, and accuracy\n",
    "\n",
    "> Answer the user's question directly, without elaboration, explanation, or details \\[...\\] \\\n",
    "> \\<example\\> \\\n",
    "> user: 2 + 2 \\\n",
    "> assistant: 4 \\\n",
    "> \\</example\\>\n",
    "\n",
    "> When making changes to files, first understand the file's code conventions. Mimic code style, use existing libraries and utilities, and follow existing patterns.\n",
    "\n",
    "> IMPORTANT: DO NOT ADD ***ANY*** COMMENTS unless asked\n",
    "\n",
    "If you are building your own assistant, the system prompt will be the starting point that will direct your assistant to the right direction.\n",
    "\n",
    "Also note that the system prompt does count towards the context window size.\n",
    "\n",
    "### Thinking modes (reasoning)\n",
    "\n",
    "Most providers will support different thinking level, in addition to the model selection. This **allocates more budget for the model to use**. The more budget the model has, the more resources it can spend into thinking about the problem. \n",
    "\n",
    "There are many types of reasoning, but a general approach is to implement a _chain of thought. _Thinking_ or _Reasoning_ is the process of breaking down problems into smaller, achievable steps, enabling the model to tackle bigger and more complex problems. This is essentially how we humans tackle problems. Because the model can prompt itself multiple times for consistency, this increase in **allocated budget will be directly linked to model cost**. [According to NVIDIA](https://www.nvidia.com/en-us/glossary/ai-reasoning/), reasoning queries may require **100 times more computing than traditional queries**.\n",
    "\n",
    "As examples, [Claude uses](https://www.anthropic.com/engineering/claude-code-best-practices) the keywords _\"think\" < \"think hard\" < \"think harder\" < \"ultrathink.\"_. [Gemini uses](https://ai.google.dev/gemini-api/docs/thinking) a number range to enable progressive thinking for the models. Models like GPT-4o are also [fine-tuned specifically](https://platform.openai.com/docs/guides/reasoning-best-practices#reasoning-models-vs-gpt-models) to act as \"the planners\". You should:\n",
    "\n",
    "- Use small models (mini, flash) for simple tasks like categorization or typo checking.\n",
    "- Use normal mode for routine tasks.\n",
    "- Use reasoning when facing complex logic or multiple-step problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed18a3e-7c2e-4ff1-bb39-24c1e7973ef8",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "At least in programming, agents are chat-based interfaces that can directly interact with your code, interact with your project, modify files and verify its own work.\n",
    "\n",
    "It tries to automate the programming workflow by giving the LLM tools to iterate on the problem to solve it.\n",
    "\n",
    "### Agent context\n",
    "\n",
    "When working with agents, you don't want to explain your project on every single request when calling the LLM: there must be a way to _instruct_ the LLM on the repository basics: how to get it running, where files are and what they do, explanation of the tech stack, etc.\n",
    "\n",
    "Which _sounds an awful lot like_ documentation. You heard it right. **The best assisted code development that you can get is with well structured, well documented projects, with plentiful developer documentation available.**\n",
    "\n",
    "Many different formats came to assist passing instructions, some like [agents.md](https://agents.md/) are generic and work for multiple agents. Some providers have specific files, Claude has `CLAUDE.md`, cursor has a `.cursor` folder with individual `RULE.md` files.\n",
    "\n",
    "Over a [blog post authored by the team at Github](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/), they also underline some specifics:\n",
    "\n",
    "#### Put commands early\n",
    "\n",
    "Commands are what tools your agent will have to solve the task at hand. Applies generally to how to start your project, **e.g.**, \"You can test the project with `pytest -v`. Ignore the tests under `tests/integration`.\"\n",
    "\n",
    "#### Code examples over explanations\n",
    "\n",
    "Rather than displaying the code style via words (we use Sphinx for documentation, we prefer that methods retrieve from database have the `get_` prefix), you might as well show this template by showcasing one of your example functions in this agent context, **e.g.**, \"When committing, use a command like `git commit -m \"fix: Fixing a TypeError that could happen from incorrectly typed variable.\"`\"\n",
    "\n",
    "#### Set clear boundaries\n",
    "\n",
    "Tell the AI what you want it to touch, and what it shouldn't. If you are making a plan, you should tell **do not modify any files**. In general, you should have rules for not opening any of the secret files with credentials, **e.g.**, stating on the instructions \"Never open or commit secrets\".\n",
    "\n",
    "#### Be specific about your stack\n",
    "\n",
    "Explain your stack covering six core areas: commands, testing, project structure, code style, git workflow, and boundaries.\n",
    "\n",
    "Instead of saying \"create me a Python project\", you should instruct further. What version, which package manager, how should the folder structure look like. **E.g.**, \"Create me a Python project using Python 3.12 for data analysis. Use `uv` as the package manager, pytest as the testing suite. Create a basic tests folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844fa64-1c41-438e-96ca-e1dcdbcd68e4",
   "metadata": {},
   "source": [
    "### Example agents.md file\n",
    "\n",
    "Adapted from Github's blog post:\n",
    "\n",
    "```markdown\n",
    "---\n",
    "name: docs_agent\n",
    "description: Expert technical writer for this project\n",
    "---\n",
    "\n",
    "You are an expert technical writer for this project.\n",
    "\n",
    "## Your role\n",
    "- You are fluent in Markdown and can read Python code\n",
    "- You write for a developer audience, focusing on clarity and practical examples\n",
    "- Your task: read code from `src/` and generate or update documentation in `docs/`\n",
    "\n",
    "## Project knowledge\n",
    "- **Project**: data analysis project.\n",
    "- **Tech Stack:** Python 3.12, UV, pytest, mkdocs for documentation generation.\n",
    "- **Library Stack:** We use pandas for data exploration, matplotlib for data visualization.\n",
    "- **File Structure:**\n",
    "  - `src/` â€“ Application source code (you READ from here)\n",
    "  - `notebooks/` - Exploration Jupyter notebooks (you READ from here)\n",
    "  - `docs/` â€“ All documentation (you WRITE to here)\n",
    "  - `tests/` â€“ Unit and Integration tests\n",
    "\n",
    "## Commands you can use\n",
    "Build docs: `mkdocs build` (checks for broken links)\n",
    "Lint markdown: `npx markdownlint docs/` (validates your work)\n",
    "\n",
    "## Documentation practices\n",
    "Be concise, specific, and value dense\n",
    "Write so that a new developer to this codebase can understand your writing, donâ€™t assume your audience are experts in the topic/area you are writing about.\n",
    "\n",
    "## Boundaries\n",
    "- âœ… **Always do:** Write new files to `docs/`, follow the style examples, run markdownlint\n",
    "- âš ï¸ **Ask first:** Before modifying existing documents in a major way\n",
    "- ðŸš« **Never do:** Modify code in `src/`, edit config files, commit secrets\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cdb053-a2f8-477e-bb54-6dda044b0f61",
   "metadata": {},
   "source": [
    "### Generating the agent context file\n",
    "\n",
    "For most agents, it is possible to generate the agents file via an `/init` command. This command will look for common patterns in your repository and try to understand your codebase programmatically.\n",
    "\n",
    "This context will be used every time the agent does a task in your project to acquire context on where things are. A well written and maintained agents file can save tokens by instructing the agent correctly from the first interaction, also **saving time, money and CO2 emissions in the process.**\n",
    "\n",
    "![](../images/claude-init.gif)\n",
    "\n",
    "Here is how the file looks like for our repository (I have omitted the non-relevant parts with `[...]`):\n",
    "\n",
    "It does start by explaining the repository overview, which is very informative when the agent later has to find the correct files again.\n",
    "\n",
    "It also describes the development workflow: how to install dependencies and to get it running.\n",
    "\n",
    "````markdown\n",
    "# CLAUDE.md\n",
    "\n",
    "This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n",
    "\n",
    "## Repository Overview\n",
    "\n",
    "This is a Python teaching repository for a data science course (_CES Python Programming - Fundamentals_) at Hochschule Albstadt Sigmaringen. The course teaches Python data analysis through interactive Jupyter notebooks with no prior programming experience assumed.\n",
    "\n",
    "## Repository Structure\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ lessons/          # 15 Jupyter notebook lessons (lesson01.ipynb - lesson14.ipynb)\n",
    "â”œâ”€â”€ assignments/      # Weekly assignment descriptions (.md files)\n",
    "â”œâ”€â”€ data/            # Datasets used in lessons and assignments\n",
    "â”œâ”€â”€ presentations/   # Course presentation materials\n",
    "â””â”€â”€ venv/           # Python virtual environment (ignored in git)\n",
    "```\n",
    "[...]\n",
    "\n",
    "## Development Workflow\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python3 -m venv venv\n",
    "\n",
    "# Activate virtual environment\n",
    "source venv/bin/activate  # macOS/Linux\n",
    "source venv/Scripts/activate  # Windows\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "[...]\n",
    "````\n",
    "\n",
    "It then summarizes the conventions: how is each notebook structured, where the assignments are located, which code style it follows.\n",
    "\n",
    "This instructs, when introducing new generated code, how it should look like, e.g. when creating a new class from scratch.\n",
    "\n",
    "Notice also how **it favours examples over explanations**, extracting one example from the material. \n",
    "\n",
    "````markdown\n",
    "### Notebook Conventions\n",
    "\n",
    "- Each lesson notebook follows a consistent structure:\n",
    "  - Introduction and learning objectives\n",
    "  - Readings and references\n",
    "  - Table of contents\n",
    "  - Detailed content with code examples\n",
    "  - Exercises (in-line within the notebook)\n",
    "\n",
    "- Assignments are in separate `.md` files in the `assignments/` directory\n",
    "[...]\n",
    "\n",
    "## Python Code Style\n",
    "\n",
    "Based on lesson 13 (clean coding), this course follows:\n",
    "\n",
    "- **PEP8** style guidelines\n",
    "- Type hints for function parameters and return values\n",
    "- Docstrings for functions and modules (see `lessons/fibo.py` for examples)\n",
    "- Meaningful variable names (avoid single-letter except for loop counters)\n",
    "\n",
    "### Example from Course Materials\n",
    "\n",
    "```python\n",
    "def fib(n: int):\n",
    "    \"\"\"\n",
    "    Write Fibonacci series up to a max value of n\n",
    "    \"\"\"\n",
    "    a, b = 0, 1\n",
    "    while b < n:\n",
    "        print(b, end=\" \")\n",
    "        a, b = b, a + b\n",
    "    print()\n",
    "```\n",
    "[...]\n",
    "````\n",
    "\n",
    "At the end, it compiles some additional information it finds relevant from the README, as well as technical information (Python version, libraries used).\n",
    "\n",
    "````markdown\n",
    "## Teaching Philosophy Notes\n",
    "\n",
    "From the README, this course emphasizes:\n",
    "\n",
    "1. Learning by doing - encourage experimentation\n",
    "2. Reading error messages and debugging\n",
    "3. Using documentation and search effectively\n",
    "4. Measured use of AI tools (lesson 14 covers proper usage)\n",
    "5. Daily practice and incremental progress\n",
    "\n",
    "When helping with course materials, maintain this hands-on, student-centered approach.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- The course uses Python 3.13+ (check `venv/` for current version)\n",
    "- Main dependencies: `ipython`, `jupyter`, `numpy`, `pandas`, `matplotlib`, `scipy`, `scikit-learn`, `prophet`\n",
    "- All notebooks should work in both local Jupyter and Google Colab environments\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d857af-7bf3-4aa7-bf41-d487f8a9c6a0",
   "metadata": {},
   "source": [
    "Now that the agent knows a bit about our project, we can try a little experiment now running the following prompt.\n",
    "\n",
    "In this example, I used Claude Code to generate lesson 15 as a demonstration:\n",
    "\n",
    "> Create a new class 15 for this repository. It should cover the most important Python dunder methods. Include graspable examples that are relevant in the real world. Be brief and do not exceed 20 code cells.\n",
    "\n",
    "![](../images/claude-plan-building.png)\n",
    "\n",
    "Notice what the thought process is:\n",
    "\n",
    "- The `CLAUDE.md` is already part of the context, as well as our memory.\n",
    "- Creates a three step plan to accomplish the task.\n",
    "- Agent then seeks additional context by scanning two of the other lessons. It already knows from the context where they are located, and how they are named.\n",
    "- With all this context at hand, generates the required output.\n",
    "- Writes final result to `lessons/lesson15.ipynb`.\n",
    "\n",
    "Here is how the final result looks like:\n",
    "\n",
    "![](../images/claude-class-building-example.png)\n",
    "\n",
    "Note also that:\n",
    "\n",
    "- It can read files from my project if it deems necessary.\n",
    "- It is able to write custom file types like `.ipynb` correctly\n",
    "- It mimics the styling of the other clases.\n",
    "- **But, it feels generic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385e0fe-fdfd-42ec-a39d-a014d3da8e74",
   "metadata": {},
   "source": [
    "### Updating agents memory\n",
    "\n",
    "You don't need to re-run the `/init` step every time your project changes. You can instruct the agent to additionally update the context files, as well as including extra information using the memory commands.\n",
    "\n",
    "The memory is nothing more than - you guessed it - more markdown files that get inserted into the context. You can also include instructions on the global level: this will be available in all your projects.\n",
    "\n",
    "Examples of agent memory:\n",
    "\n",
    "- **Styling**: When you create a bullet point list, always include the period at the end of the line.\n",
    "- **Tool usage**: I have `glab` CLI configured for all repositories hosted on Gitlab.\n",
    "- **Boundaries**: Do not execute docker compose commands (up, down, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239eefa0-f447-4122-9fcf-54d24e448cfa",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "One of the key advantages of modern AI agents is their ability to use **tools** - external capabilities that extend beyond text generation. While LLMs by themselves can only generate text, tools allow them to interact with the real world: read files, execute code, search the web, run calculations, and much more.\n",
    "\n",
    "### How tools work\n",
    "\n",
    "When you ask an agent to \"read the file data.csv\", the LLM doesn't magically access your filesystem. Instead:\n",
    "\n",
    "1. The agent recognizes it needs to read a file.\n",
    "2. It calls a **read file tool** with the path parameter.\n",
    "3. The tool executes and returns the file contents.\n",
    "4. The agent receives this information and continues its task.\n",
    "\n",
    "This solves many of the limitations we discussed earlier:\n",
    "- **Arithmetic calculations**: The agent can call a calculator tool.\n",
    "- **Current information**: The agent can search the web.\n",
    "- **Code correctness**: The agent can execute code and see if it works.\n",
    "- **File operations**: The agent can read, write, and modify files.\n",
    "\n",
    "### Common tool categories\n",
    "\n",
    "Here are some typical tools that agents have access to:\n",
    "\n",
    "**File operations:**\n",
    "- Read, write and edit files (source code, data files, documentation)\n",
    "- Search for files matching patterns (e.g., find all `.py` files)\n",
    "- Search within files (e.g., find where function `foo` is defined)\n",
    "\n",
    "**Code execution:**\n",
    "- Run bash commands\n",
    "- Execute Python scripts\n",
    "- Run tests\n",
    "- Install packages\n",
    "- Start servers or applications\n",
    "\n",
    "**Information retrieval:**\n",
    "- Web search (Google, Bing, etc.)\n",
    "- Fetch content from URLs\n",
    "- Read API documentation\n",
    "\n",
    "**Development tools:**\n",
    "- Git operations (commit, push, create branches)\n",
    "- Create pull requests\n",
    "- Run linters and formatters\n",
    "\n",
    "### MCP Servers (Model Context Protocol)\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an open standard developed [by Anthropic](https://www.anthropic.com/news/model-context-protocol) that allows AI agents to securely connect to external data sources and tools.\n",
    "\n",
    "The key advantage of MCP is **standardization**: instead of each AI provider creating custom integrations, MCP provides a universal way for any AI agent to connect to any data source. This means you can use the same MCP server with Claude, ChatGPT, or any other compatible AI tool. Think of it as the USB-C port for AI Applications.\n",
    "\n",
    "\n",
    "<a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\">\n",
    "  <center><img src=\"../images/mcp-simple-diagram.png\" width=\"60%\"/></center>\n",
    "</a>\n",
    "\n",
    "\n",
    "\n",
    "An example for a useful MCP Server is [Context7](https://context7.com/), a tool that allows you to get up-to-date documentation for libraries, avoiding the issue with the training data being outdated.\n",
    "\n",
    "### Tools in practice for data science\n",
    "\n",
    "Without tools (chat only):\n",
    "\n",
    "```\n",
    "You: \"Analyze the dataset in data/sales.csv\"\n",
    "AI: \"I cannot access files. Please copy the contents here.\"\n",
    "[You copy-paste 5000 rows...]\n",
    "AI: [Might hit context limits, cannot verify code works]\n",
    "```\n",
    "\n",
    "With tools (agentic mode):\n",
    "\n",
    "```\n",
    "You: \"Analyze the dataset in data/sales.csv\"\n",
    "AI: [Reads file using file tool]\n",
    "AI: [Examines structure, identifies columns]\n",
    "AI: [Writes analysis script]\n",
    "AI: [Executes script using code execution tool]\n",
    "AI: [Sees error, fixes it, re-runs]\n",
    "AI: \"Here's your analysis with visualizations in output/sales_analysis.png\"\n",
    "```\n",
    "\n",
    "The agent can iterate, verify its work, and deliver working solutions because it has the tools to interact with your actual development environment.\n",
    "\n",
    "### Security and boundaries\n",
    "\n",
    "<center><img src=\"../images/claude-wiped-my-mac.png\" width=\"60%\"/></center>\n",
    "\n",
    "With great power comes great responsibility. Tools can:\n",
    "- Delete files\n",
    "- Execute arbitrary code\n",
    "- Access sensitive data\n",
    "- Make API calls that cost money\n",
    "\n",
    "This is why:\n",
    "1. **You control what tools agents can access** - Most systems require you to explicitly grant permissions\n",
    "2. **Agent context files set boundaries** - Your CLAUDE.md or agents.md should specify what the agent should and shouldn't touch\n",
    "3. **You should review sensitive operations** - Many agents will ask before making destructive changes\n",
    "4. **Never give agents access to production systems** - Work in development environments\n",
    "\n",
    "Remember: the agent is a tool that executes your instructions. You remain responsible for what it does in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u5jb4286n9",
   "metadata": {},
   "source": [
    "## Ethics and Sustainability\n",
    "\n",
    "AI is a powerful tool, but with power comes responsibility. As data scientists and developers, we need to consider both the ethical implications and environmental impact of our AI usage.\n",
    "\n",
    "As an example, the [linked article from MIT Technology review](https://www.technologyreview.com/2025/05/20/1116327/ai-energy-usage-climate-footprint-big-tech/) shows that the surge in the demand for computing power makes data centers consume 4.4% of the electricity available in the US, with a carbon intensity almost 50% higher than the US average.\n",
    "\n",
    "### When NOT to use AI\n",
    "\n",
    "There are scenarios where AI assistance is inappropriate or even dangerous:\n",
    "\n",
    "- **When working with sensitive data**: Your data gets uploaded to external data providers, including your business logic. Never paste confidential data, personal information, or trade secrets into public AI services.\n",
    "- **Academic integrity:**: Using AI to complete assignments without understanding violates academic integrity. **Acceptable:** \"Explain how groupby works in pandas\". **Unacceptable:** \"Complete my assignment and write the report\".\n",
    "- **Critical decision-making:**: Don't rely solely on AI for decisions affecting people's lives, safety, or livelihoods. In data science: AI can help analyze data, but you must verify conclusions before acting on them\n",
    "- **High-stakes production code:** AI-generated code for security-critical systems needs extensive review. Never deploy AI-generated code to production without testing and human verification.\n",
    "\n",
    "### Always verify the output\n",
    "\n",
    "You are responsible for every line of code you use, whether you wrote it or AI did.\n",
    "\n",
    "- If you cannot explain your code, then is not useful code. Try again.\n",
    "- Verify citations actually exist, preferably consulting them yourself.\n",
    "- Check for security vulnerabilities (SQL injection, XSS, etc.).\n",
    "- Be skeptical of what it generates. LLMs are very good at generating text, that even non-sense might _look_ belieable.\n",
    "- Use AI-generated content as a starting point, not the final word.\n",
    "\n",
    "### Environmental impact\n",
    "\n",
    "AI has a significant environmental footprint that we should be mindful of:\n",
    "\n",
    "- According to research, AI queries use significantly more energy than traditional searches.\n",
    "- Training large models requires massive computational resources.\n",
    "- Reasoning/thinking modes can use 100x more compute than standard queries.\n",
    "- Data centers running AI contribute to CO2 emissions and water usage.\n",
    "\n",
    "So you should:\n",
    "\n",
    "- **Think before you prompt**: Formulate clear, specific prompts to avoid multiple iterations. Sometimes, you don't even need to prompt. \n",
    "- **Use appropriate models**: Don't use heavyweight reasoning for simple questions.\n",
    "- **Prefer efficient modes**: Chat and IDE plugins are often more efficient than repeated web queries.\n",
    "- **Batch your questions**: Ask multiple related questions in one prompt instead of many small queries.\n",
    "\n",
    "### Finding the balance\n",
    "\n",
    "AI is neither a magical solution nor something to be feared. It is a tool:\n",
    "\n",
    "- **Use AI to augment your capabilities**, not replace your thinking.\n",
    "- **Apply it to appropriate problems** where it can genuinely help.\n",
    "- **Verify outputs** and take responsibility for what you deploy.\n",
    "- **Consider the broader impacts** - ethical, environmental, social.\n",
    "- **Keep learning and adapting** as the technology evolves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
